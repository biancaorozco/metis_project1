{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTA Data Source:http://web.mta.info/developers/turnstile.html\n",
    "\n",
    "\n",
    "Data dictionary:    \n",
    "C/A      = Control Area (a block of turnstiles);\n",
    "UNIT     = Remote Unit for a station;\n",
    "SCP      = Subunit Channel Position (designates a single turnstile);\n",
    "STATION  = Station name;\n",
    "LINENAME = Concatenation of names of lines going through station (e.g. NQR456, BD,...);\n",
    "DIVISION = A label with six possible values:\n",
    "          The first three refer to a time when there were three separate subway systems:  \n",
    "             IRT = Interborough Rapid Transit;  \n",
    "             BMT = Brooklyn-Manhattan Transit;  \n",
    "             IND = Independent Subway;  \n",
    "          The last three are more recent developments:\n",
    "             PTH = Port Authority Trans-Hudson (PATH);\n",
    "             RIT = Roosevelt Island Tram;\n",
    "             SRT = Staten Island Rapid Transit;\n",
    "DATE     = Date on which data were collected;\n",
    "TIME     = Time of collection (every four hours);\n",
    "DESC     = Characterizes the audit event as either:\n",
    "          REGULAR (normally every four hours), or\n",
    "          RECOVR AUD (a missed audit that was recovered);\n",
    "ENTRIES  = State of entries counter at turnstile at given date and time;\n",
    "EXITS    = State of exits counter at turnstile at given date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "baseURL = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_\"\n",
    "#start_date = date(2019, 9, 21) # 21st September 2019\n",
    "start_date = date(2019, 6, 1) # 1st June 2019\n",
    "\n",
    "############## Helper Functions ##############\n",
    "def string_of_weeks(start_date, number_of_weeks):\n",
    "    '''\n",
    "    Returns a list of strings where each string represents a date in \"yymmdd\" format\n",
    "    Starting with the \"start_date\"\n",
    "    start_date should be a date object\n",
    "    '''\n",
    "    #print(start_date.strftime(\"%y%m%d\")) #for testing\n",
    "    a_week = timedelta(days=7)\n",
    "    \n",
    "    list_of_dates = list([start_date.strftime(\"%y%m%d\")])\n",
    "    \n",
    "    #Works but not readable\n",
    "    #list_of_dates += ([(d-week*a_week).strftime(\"%y%m%d\") for week in range(1,number_of_weeks)])\n",
    "    \n",
    "    assert number_of_weeks >= 1\n",
    "    \n",
    "    for week in range(1, number_of_weeks):\n",
    "        temp = start_date - week * a_week # a number * timedelta to walk backwards in time\n",
    "        list_of_dates.append(temp.strftime(\"%y%m%d\"))\n",
    "    \n",
    "    return list_of_dates\n",
    "\n",
    "#print(string_of_weeks(start_date, 52)) #for testing\n",
    "\n",
    "def create_MTA_dataframe(start_date, number_of_weeks):\n",
    "    '''\n",
    "    Returns a panda DataFrame object of MTA turnstile data starting from\n",
    "    start_date and going back to number_of_weeks\n",
    "    '''    \n",
    "    dates_for_downloads = string_of_weeks(start_date, number_of_weeks)\n",
    "    print(dates_for_downloads)\n",
    "    list_of_sizes = []\n",
    "    \n",
    "    # --- Read the csv file for the first week & strip any whitespaces in the column names\n",
    "    mta_df = pd.read_csv(baseURL+dates_for_downloads[0]+\".txt\")\n",
    "    mta_df.rename(columns = lambda col: col.strip(), inplace=True)\n",
    "    list_of_sizes.append(mta_df.shape[0])\n",
    "    #print(type(mta_df)) #for testing\n",
    "    \n",
    "    # --- Read the csv file for the rest of the weeks in the dates list\n",
    "    #    & strip any whitespaces in the column names before appending\n",
    "    for week in dates_for_downloads[1:]:\n",
    "        temp = pd.read_csv(baseURL+week+\".txt\")\n",
    "        temp.rename(columns = lambda col: col.strip(), inplace=True)\n",
    "        mta_df = mta_df.append(temp, ignore_index=True)\n",
    "        #print(\"Added one dataframen for: \" + week+\" with rows:\"+ str(temp.shape[0]))\n",
    "        list_of_sizes.append(temp.shape[0])\n",
    "        \n",
    "    \n",
    "    mta_df.info()\n",
    "    #print(list_of_sizes)\n",
    "    #print(len(list_of_dfs))\n",
    "    return mta_df\n",
    "\n",
    "def add_a_key(list_column_names, mta_data):\n",
    "    \"\"\"\n",
    "    Adds a \"key\" column by concatenating the columns specified in the \"list_column_names\"\n",
    "    Example: To specify \"C/A\" & \"STATION\" as keys, call this function using [\"C/A\", \"STATION\"]\n",
    "             for \"list_column_names\"\n",
    "    \n",
    "    returns a pandas DataFrame\n",
    "    \"\"\"\n",
    "    #print(list_column_names)  # for testing\n",
    "    \n",
    "    # --- Delete the \"key\" column if exist & create a brand new key column with empty strings\n",
    "    if \"turnstile_key\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"turnstile_key\", axis=1)\n",
    "    mta_data[\"turnstile_key\"] = \"\"\n",
    "    \n",
    "    # --- If column name correctly specified and it exists, then add its value to the key\n",
    "    for col in list_column_names:\n",
    "        try:\n",
    "            if col in list(mta_data.columns):\n",
    "                mta_data[\"turnstile_key\"] += mta_data[col]\n",
    "        except:\n",
    "            print(\"Column {} does not exist in the DataFrame\".format(col))\n",
    "            return None\n",
    "    \n",
    "    return mta_data\n",
    "\n",
    "def add_times_columns(mta_data):\n",
    "    \"\"\"\n",
    "    Adds date/time/day of week/AM-PM columns\n",
    "    Combines the \"DATE\" and \"TIME\" fields into a single colummn of \"DATETIME\" of datetime data type\n",
    "    \n",
    "    Retunrs a pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_cols = [\"DATETIME\", \"DAY_OF_THE_WEEK\", \"AM/PM\"]\n",
    "    # --- Delete the time columns if they already exist\n",
    "    for col in list_of_cols:\n",
    "        if col in list(mta_data.columns):\n",
    "            mta_data.drop(col, axis=1)    \n",
    "    \n",
    "    # --- DATETIME: Uses parser method from dateutil python library\n",
    "    #     to convert a string into datetime object  \n",
    "    #\n",
    "    # Would this work? mta_data[\"DATETIME\"]=dt.to_datetime(mta_data[\"DATE\"]+\" \"+mta_data[\"TIME\"])\n",
    "    #\n",
    "    mta_data[\"DATETIME\"]=[parse(i) for i in (mta_data[\"DATE\"]+\" \"+mta_data[\"TIME\"])]\n",
    "    \n",
    "    # --- DAY_OF_THE_WEEK: Using standard datetime utils from pandas\n",
    "    #     to get day of the week from a datetime column\n",
    "    mta_data[\"DAY_OF_THE_WEEK\"]=mta_data[\"DATETIME\"].dt.weekday_name\n",
    "    \n",
    "    # --- AM/PM\n",
    "    #     Gets AM/PM from a datetime field   \n",
    "    mta_data[\"AM/PM\"]=[datetime.strftime(dtime, \"%p\") for dtime in mta_data[\"DATETIME\"]]\n",
    "    \n",
    "    # --- Hour\n",
    "    #     Adds Hour field   \n",
    "    mta_data['HOUR'] = mta_data['DATETIME'].dt.hour\n",
    "    \n",
    "    return mta_data\n",
    "\n",
    "def add_previous(mta_data):\n",
    "    \"\"\"\n",
    "    Adds the following column data from previous timestamp rows for any turnstile\n",
    "    \"DATETIME\" ==> \"prev_datetime\"\n",
    "    \"TIMESTAMP\" ==> \"prev_tstamp\"\n",
    "    \"ENTRIES\" ==> \"prev_entries\"\n",
    "    \"EXITS\" ==> \"prev_exits\"\n",
    "    \n",
    "    'Previous' data is added for multiple columns for data checks and filtering\n",
    "    \"\"\"\n",
    "    #source_prev_cols = [\"DATETIME\", \"tunrstile_key\",\"ENTRIES\", \"EXITS\"]\n",
    "    \n",
    "    prev_column_list = [\"prev_datetime\", \"prev_key\", \n",
    "                        \"prev_entries\", \"prev_exits\",\n",
    "                        \"inSeq\", \"time_step\", \"DiffEntries\"]\n",
    "    # --- Delete the prev columns if they already exist\n",
    "    for col in prev_column_list:\n",
    "        if col in list(mta_data.columns):\n",
    "            mta_data.drop(col, axis=1)\n",
    "    '''\n",
    "    # --- Delete any \"prev\" columns if exist, ugly version\n",
    "    if \"prev_datetime\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"prev_datetime\")    \n",
    "    if \"prev_key\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"prev_key\")\n",
    "    if \"prev_entries\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"prev_entries\")\n",
    "    if \"prev_exits\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"prev_exits\")\n",
    "    if \"inSeq\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"inSeq\")\n",
    "    if \"time_step\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"time_step\")\n",
    "    if \"DiffEntries\" in list(mta_data.columns):\n",
    "        mta_data.drop(\"DiffEntries\")\n",
    "    '''\n",
    "    # --- sort the dataframe first, so you have rows lined up for getting the previous rows\n",
    "    mta_data.sort_values(by=[ \"turnstile_key\", \"DATETIME\"], ascending = [True, True], inplace=True)\n",
    "    \n",
    "    mta_data[\"prev_datetime\"] = mta_data[\"DATETIME\"].shift(periods=1)\n",
    "    mta_data[\"prev_key\"] = mta_data[\"turnstile_key\"].shift(periods=1)\n",
    "    mta_data[\"prev_entries\"] = mta_data[\"ENTRIES\"].shift(periods=1)\n",
    "    mta_data[\"prev_exits\"] = mta_data[\"EXITS\"].shift(periods=1)\n",
    "    mta_data[\"inSeq\"] = (mta_data[\"prev_datetime\"] < mta_data[\"DATETIME\"]) & (mta_data[\"prev_key\"] == mta_data[\"turnstile_key\"])\n",
    "    mta_data[\"DiffEntries\"]=(mta_data[\"ENTRIES\"]-mta_data[\"prev_entries\"]) * mta_data[\"inSeq\"]\n",
    "    mta_data[\"DiffExits\"]=(mta_data[\"EXITS\"]-mta_data[\"prev_exits\"]) * mta_data[\"inSeq\"]\n",
    "    mta_data[\"time_step\"] = (mta_data[\"DATETIME\"] - mta_data[\"prev_datetime\"]) * mta_data[\"inSeq\"]\n",
    "    \n",
    "    return mta_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(mta_data):\n",
    "    ''' Function to clean the positive and negative turnstile counts\n",
    "    \n",
    "    Args: A pandas DataFrame with turnstile entries and exits processed \n",
    "    \n",
    "    Returns: A pandas DataFrame with outlier turnstile entries and exits removed\n",
    "    \n",
    "    Filters:\n",
    "        1. \"time_step_hrs\" the interval between successive turnstile counts less than 5hrs\n",
    "           (to avoid malfunctioned turnstiles) \n",
    "        2. processed entries and exits that are greater than zero & less than 15000    \n",
    "    '''\n",
    "    \n",
    "    mta_data[\"time_step_hrs\"]  = (mta_data[\"time_step\"]/np.timedelta64(1, 'h'))\n",
    "    \n",
    "    filter_time_steps   = (mta_df_wPrev[\"time_step_hrs\"] <= 5.0) \n",
    "    filter_diff_entries = ((mta_df_wPrev[\"DiffEntries\"] >= 10000) & (mta_df_wPrev[\"DiffEntries\"] < 20000))\n",
    "    filter_diff_exits = ((mta_df_wPrev[\"DiffExits\"] >= 0) & (mta_df_wPrev[\"DiffExits\"] < 20000))\n",
    "\n",
    "    return mta_data.loc[filter_time_steps & filter_diff_entries & filter_diff_exits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_neg_positive_turnstiles(mta_data):\n",
    "    \"\"\"Creates a list of turnstiles that have negative processed entries/exits\n",
    "    \n",
    "    Args: A pandas DataFrame with processed entries and exits\n",
    "    \n",
    "    Returns: A tuple two lists: one with turnstile keys that have atleast one negative entry, and one \n",
    "             with turnstiles without any negative numbers\n",
    "    \"\"\"\n",
    "    # --- Filter for turnstiles with negative entries or exits to catch counter resets\n",
    "    filter_for_negs = (mta_data[\"DiffEntries\"] < 0) | (mta_data[\"DiffExits\"] < 0)\n",
    "    neg_turnstiles = mta_data[filter_for_negs]['turnstile_key'].unique()\n",
    "    \n",
    "    pos_turnstiles = list(uniq_keys)\n",
    "    for neg_turn in neg_turnstiles:\n",
    "        pos_turnstiles.remove(neg_turn)\n",
    "        #print(neg_turn)\n",
    "    print(len(pos_turnstiles))\n",
    "    \n",
    "    return (neg_turnstiles, pos_turnstiles)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['190601', '190525', '190518', '190511', '190504', '190427', '190420', '190413', '190406']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1840863 entries, 0 to 1840862\n",
      "Data columns (total 11 columns):\n",
      "C/A         object\n",
      "UNIT        object\n",
      "SCP         object\n",
      "STATION     object\n",
      "LINENAME    object\n",
      "DIVISION    object\n",
      "DATE        object\n",
      "TIME        object\n",
      "DESC        object\n",
      "ENTRIES     int64\n",
      "EXITS       int64\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 154.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1. Download data\n",
    "# --- Step 2. Add a key to identify turnstile\n",
    "# --- Step 3. Add time related columns\n",
    "# --- Step 4. Add columns that shifts the rows by one - calling these \"prev\" for previous timestamp values\n",
    "#\n",
    "mta_df = create_MTA_dataframe(start_date, 9)\n",
    "mta_df_wKey = add_a_key([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"], mta_df)\n",
    "mta_df_wTimestamp = add_times_columns(mta_df_wKey)\n",
    "mta_df_wPrev = add_previous(mta_df_wTimestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique C/A: 745\n",
      "Number of unique UNIT: 468\n",
      "Number of unique SCP: 223\n",
      "Number of unique STATION: 378\n",
      "Number of unique LINENAME: 114\n",
      "Number of unique Turnstile key: 4892\n"
     ]
    }
   ],
   "source": [
    "# --- Stats about the data:\n",
    "#\n",
    "#\n",
    "uniq_CAs = mta_df_wTimestamp['C/A'].unique()\n",
    "uniq_units = mta_df_wTimestamp['UNIT'].unique()\n",
    "uniq_scps = mta_df_wTimestamp['SCP'].unique()\n",
    "uniq_stations = mta_df_wTimestamp['STATION'].unique()\n",
    "uniq_linenames = mta_df_wTimestamp['LINENAME'].unique()\n",
    "uniq_divis = mta_df_wTimestamp['LINENAME'].unique()\n",
    "uniq_keys = mta_df_wTimestamp['turnstile_key'].unique()\n",
    "\n",
    "print(\"Number of unique C/A: \"+str(len(uniq_CAs)))\n",
    "print(\"Number of unique UNIT: \"+str(len(uniq_units)))\n",
    "print(\"Number of unique SCP: \"+str(len(uniq_scps)))\n",
    "print(\"Number of unique STATION: \"+str(len(uniq_stations)))\n",
    "print(\"Number of unique LINENAME: \"+str(len(uniq_linenames)))\n",
    "print(\"Number of unique Turnstile key: \"+str(len(uniq_keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summation_of_passengers(mta_data):\n",
    "    '''\n",
    "    Input: MTA dataframe \n",
    "    Output: Adding a new column with the sum of DiffEntries+DiffExits called PASSENGERS\n",
    "    \n",
    "    '''\n",
    "    col_list = ['DiffEntries', 'DiffExits']\n",
    "    \n",
    "    mta_data['PASSENGERS'] = mta_data[col_list].sum(axis=1)\n",
    "    \n",
    "    \n",
    "#     empty_col = []\n",
    "#     for i,j in mta_data['DiffEntries'], mta_data['DiffExits']:\n",
    "#         empty_col.append(i+j)\n",
    "    \n",
    "    return mta_data\n",
    "    \n",
    "\n",
    "def creating_final_df(mta_data, string_col_names):\n",
    "    '''\n",
    "    Input: MTA dataframe and a list of string of column names you want from the new dataframe\n",
    "    Output: A clean dataframe with the following columns...\n",
    "        columns: STATION, DAY_OF_THE_WEEK, HOUR, PASSENGERS\n",
    "    '''\n",
    "    #appending_cols(string_col_names)\n",
    "    \n",
    "    mta_final = pd.DataFrame()\n",
    "    \n",
    "    for colname in string_col_names:\n",
    "        mta_final[colname] = mta_data[colname]    \n",
    "    \n",
    "    return mta_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "summation_of_passengers(mta_df_wPrev)\n",
    "mta_final = creating_final_df(mta_df_wPrev, ['STATION', 'DAY_OF_THE_WEEK', 'HOUR', 'PASSENGERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DAY_OF_THE_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>PASSENGERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1637899</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1637900</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>4</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1637901</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>8</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1637902</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>12</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1637903</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203790</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203791</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203792</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>Friday</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203793</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>Friday</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203794</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1840863 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               STATION DAY_OF_THE_WEEK  HOUR  PASSENGERS\n",
       "1637899          59 ST        Saturday     0         0.0\n",
       "1637900          59 ST        Saturday     4        28.0\n",
       "1637901          59 ST        Saturday     8        69.0\n",
       "1637902          59 ST        Saturday    12       195.0\n",
       "1637903          59 ST        Saturday    16       308.0\n",
       "...                ...             ...   ...         ...\n",
       "203790   RIT-ROOSEVELT          Friday     9         0.0\n",
       "203791   RIT-ROOSEVELT          Friday    12         0.0\n",
       "203792   RIT-ROOSEVELT          Friday    13         0.0\n",
       "203793   RIT-ROOSEVELT          Friday    17         0.0\n",
       "203794   RIT-ROOSEVELT          Friday    21         0.0\n",
       "\n",
       "[1840863 rows x 4 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mta_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
